{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "np.random.seed(2012)\n",
    "\n",
    "# Configure visual settings:\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "plt.style.use(['bmh'])\n",
    "\n",
    "# Load the dataframe\n",
    "\n",
    "data = pd.read_pickle(r'assets/NLP_data.p')\n",
    "\n",
    "# Import lists of variable names\n",
    "with open('var_names.p', 'rb') as f:\n",
    "    target_variables, predictor_variables, categorical_variables, numerical_variables, text_variables, ordinal_variables = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No boxes OR furniture listed. Keep only those rows with either non-empty furniture list\n",
    "# or non-null box count!\n",
    "data = data[(data['furniture'] != '') | (~data['boxes'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate                       152\n",
       "num_noun_phrases             0\n",
       "loc1.stairs                  0\n",
       "loc1.elevatorType_Large      0\n",
       "loc2.rooms                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle null values once and for all here. Easily revisit-able in order to do more advanced imputation.\n",
    "\n",
    "# Est_hours and num_movers are important target variables. I can't do without them!\n",
    "data.dropna(subset=['est_hours','num_movers'], inplace=True)\n",
    "\n",
    "# It is curious why we don't have info for the rate sometimes. Are these free moves? If they were for charity\n",
    "# or for non-residential, I should have weeded them out sooner. I probably won't be doing anything with rate \n",
    "# for the time being though, so it doesn't matter.\n",
    "\n",
    "# If travel_fee is blank, simply assume there wasn't one. This is a very good guess.\n",
    "data['travel_fee'].fillna(0, inplace=True)\n",
    "\n",
    "# If no boxes listed, assume furniture only.\n",
    "data['boxes'].fillna(0, inplace=True)\n",
    "\n",
    "# Some variable will just be median-imputed for now. They are the ones that can be imputed \n",
    "# more artfully later on:\n",
    "median_imputation_variables = ['loc1.sqFt','loc2.sqFt','loc1.lengthOfWalkOptID','loc2.lengthOfWalkOptID']\n",
    "\n",
    "for col in median_imputation_variables:\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "\n",
    "data.isnull().sum().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(data, test_size=.2, stratify=data['truck_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "table      20363\n",
       "chair      13735\n",
       "small      10528\n",
       "bed         9435\n",
       "dresser     7270\n",
       "tv          7264\n",
       "large       5981\n",
       "desk        5896\n",
       "queen       5481\n",
       "dining      5138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do count vectorizing:\n",
    "\n",
    "# Define tokenizer:\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "# Get only words, and stem:\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def my_tokenizer(string):\n",
    "    tokens = tokenizer.tokenize(string)\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    lemmas = [x for x in lemmas if len(x)>1]\n",
    "    return(lemmas)\n",
    "\n",
    "# Do count vectorizer:\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvt = CountVectorizer(stop_words='english', max_features = 100, tokenizer=my_tokenizer)\n",
    "X = cvt.fit_transform(training_data['furniture'])\n",
    "\n",
    "cvt_training_data = pd.DataFrame(X.A, columns=cvt.get_feature_names())\n",
    "\n",
    "cvt_training_data.columns\n",
    "\n",
    "assert cvt_training_data.shape[0] == training_data.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "training_data = training_data.reset_index().join(cvt_training_data, rsuffix='_')\n",
    "\n",
    "cvt_training_data.sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "table      5057\n",
       "chair      3517\n",
       "small      2563\n",
       "bed        2362\n",
       "dresser    1868\n",
       "tv         1862\n",
       "large      1620\n",
       "desk       1553\n",
       "queen      1368\n",
       "dining     1308\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cvt.transform(testing_data['furniture'])\n",
    "\n",
    "cvt_testing_data = pd.DataFrame(X.A, columns=cvt.get_feature_names())\n",
    "\n",
    "cvt_testing_data.columns\n",
    "\n",
    "assert cvt_testing_data.shape[0] == testing_data.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "testing_data = testing_data.reset_index().join(cvt_testing_data, rsuffix='_')\n",
    "\n",
    "cvt_testing_data.sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Little    6490\n",
       "Big       2944\n",
       "Name: truck_type, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['truck_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Little    1623\n",
       "Big        736\n",
       "Name: truck_type, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data['truck_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data.to_pickle('assets/training_data.p')\n",
    "testing_data.to_pickle('assets/testing_data.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
